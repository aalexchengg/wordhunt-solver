{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*TODO*\n",
        "\n",
        "*   weird looking boards\n",
        "*   rnn???? / new way to implement the solver\n",
        "*   classifier (is the board easy, medium, or hard??) ideas could involve looking at runtime, straight up the content of the board, or outputs of alexei/someone else\n",
        "*   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-VvKS9X1w70i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su3zW5IEm3P2"
      },
      "outputs": [],
      "source": [
        "from collections import Counter, defaultdict\n",
        "from itertools import product\n",
        "import math\n",
        "import io\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PREPROCESSING\n",
        "def get_ngrams(path, n):\n",
        "  result = []\n",
        "  with open(path) as input:\n",
        "    for line in input:\n",
        "      if(len(line)<3 or len(line)>16):\n",
        "        continue\n",
        "      line = \"0\" + line\n",
        "      for i in range(len(line) - (n-1)):\n",
        "        result.append((line[i:i+n]))\n",
        "  return result\n",
        "\n",
        "\n",
        "def post_process(input):\n",
        "  result = []\n",
        "  for value in input:\n",
        "    result.append(value[1:-1])\n",
        "  return result"
      ],
      "metadata": {
        "id": "ZUTujwufng2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#HELPER FUNCTIONS\n",
        "\n",
        "#turns a 2d matrix into an adjacency list of indeces\n",
        "def board_to_adjlist(board):\n",
        "    result = dict()\n",
        "    for i in range(len(board)):\n",
        "        for j in range(len(board[0])):\n",
        "            idx = (i,j)\n",
        "            neighbors = []\n",
        "            for x in range(-1,2):\n",
        "                for y in range(-1,2):\n",
        "                    if(not(x == 0 and y ==0)):\n",
        "                        if(x + i >=0 and y + j >=0 and x + i < len(board) and y + j < len(board[0])):\n",
        "                            neighbors.append((i+x,j+y))\n",
        "            result[idx] = neighbors\n",
        "    return result\n",
        "\n",
        "#turns a 2d matrix into a list of characters\n",
        "def board_to_list(board):\n",
        "  result = []\n",
        "  for row in board:\n",
        "    result = result + row\n",
        "  result.sort()\n",
        "  return result\n",
        "\n",
        "def board_to_dict(board):\n",
        "  result = dict()\n",
        "  for i in range(len(board)):\n",
        "    for j in range(len(board[0])):\n",
        "      if(board[i][j] not in result):\n",
        "        result[board[i][j]] = [(i,j)]\n",
        "      else:\n",
        "        result[board[i][j]].append((i,j))\n",
        "  return result\n",
        "\n",
        "def exists(word, chars):\n",
        "  #REQUIRES: char is sorted\n",
        "  word = list(word)\n",
        "  word.sort()\n",
        "  curr = 0\n",
        "  i = 0\n",
        "  length = len(chars)\n",
        "  goal = len(word)\n",
        "  while(i < length):\n",
        "    if(curr == goal):\n",
        "      return True\n",
        "    if(word[curr] == chars[i]):\n",
        "      curr +=1\n",
        "    elif(word[curr] < chars[i]):\n",
        "      return False\n",
        "    i +=1\n",
        "  return curr == goal \n",
        "\n",
        "def validate(dictionary, result):\n",
        "  res = []\n",
        "  for word in result:\n",
        "    if(dictionary.get_word(word)):\n",
        "      res.append(word)\n",
        "  return res \n",
        "\n",
        "## CODE FOR TESTING ##\n",
        "\n",
        "# prepares the dict of letters to scrabble freqs that we use in the next function\n",
        "def generate_scrabble_freqs():\n",
        "  scrabble_freqs = {\n",
        "      'e': 12.49,\n",
        "      't':  9.28,\n",
        "      'a':  8.04,\n",
        "      'o':  7.64,\n",
        "      'i':  7.57,\n",
        "      'n':  7.23,\n",
        "      's':  6.51,\n",
        "      'r':  6.28,\n",
        "      'h':  5.05,\n",
        "      'l':  4.07,\n",
        "      'd':  3.82,\n",
        "      'c':  3.34,\n",
        "      'u':  2.73,\n",
        "      'm':  2.51,\n",
        "      'f':  2.40,\n",
        "      'p':  2.14,\n",
        "      'g':  1.87,\n",
        "      'w':  1.68,\n",
        "      'y':  1.66,\n",
        "      'b':  1.48,\n",
        "      'v':  1.05,\n",
        "      'k':  0.54,\n",
        "      'x':  0.23,\n",
        "      'j':  0.16,\n",
        "      'q':  0.12,\n",
        "      'z':  0.09\n",
        "  }\n",
        "  scrabble_freqs = dict(sorted(scrabble_freqs.items(), key=lambda x:x[1]))\n",
        "  index = -1\n",
        "  preventry = \"\"\n",
        "  for entry in scrabble_freqs:\n",
        "    scrabble_freqs[entry[0]] = round(scrabble_freqs[entry[0]] * 100)\n",
        "    # if the previous entry exists, add it to the current entry\n",
        "    if(index >= 0):\n",
        "      scrabble_freqs[entry[0]] = scrabble_freqs[entry[0]] + scrabble_freqs[preventry]\n",
        "    index += 1\n",
        "    preventry = entry[0]\n",
        "  return scrabble_freqs\n",
        "\n",
        "#generates number_of_boards boards with dimensions x by y\n",
        "def generate_random_boards(number_of_boards, x, y):\n",
        "  letter_freqs = generate_scrabble_freqs()\n",
        "  boards = []\n",
        "  for i in range(number_of_boards):\n",
        "    boards.append([[0]*y for i in range(x)])\n",
        "    # fill up the board w/random letters\n",
        "    for j in range(x):\n",
        "      for k in range(y):\n",
        "        # generate random letter\n",
        "        seed = random.randint(0,9998)\n",
        "        letter = ''\n",
        "        for l in letter_freqs:\n",
        "          if(seed <= letter_freqs[l]):\n",
        "            letter = l\n",
        "            break\n",
        "        assert(letter != '')\n",
        "        boards[i][j][k] = letter.upper()\n",
        "  return boards\n",
        "\n",
        "def precision(sols, ref_sols):\n",
        "  prec = 0\n",
        "  if(len(sols) == 0):\n",
        "    return 0\n",
        "  for word in sols:\n",
        "    if(word in ref_sols):\n",
        "      prec += 1\n",
        "  return prec/len(sols)\n",
        "\n",
        "def recall(sols, ref_sols):\n",
        "  rec = 0\n",
        "  if(len(ref_sols) == 0):\n",
        "    return 0\n",
        "  for word in ref_sols:\n",
        "    if(word in sols):\n",
        "      rec += 1\n",
        "  return rec/len(ref_sols)"
      ],
      "metadata": {
        "id": "f6In1_lC07Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_random_boards(2,4,4)"
      ],
      "metadata": {
        "id": "k2SbTi9gmExW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65063a9e-3e50-4e00-a5cf-671f49e95236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['E', 'I', 'E', 'O'],\n",
              "  ['H', 'T', 'B', 'H'],\n",
              "  ['O', 'T', 'E', 'A'],\n",
              "  ['N', 'G', 'T', 'E']],\n",
              " [['R', 'L', 'T', 'T'],\n",
              "  ['E', 'D', 'H', 'I'],\n",
              "  ['P', 'L', 'C', 'E'],\n",
              "  ['E', 'M', 'H', 'T']]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Literal Hash Dictionary"
      ],
      "metadata": {
        "id": "J0OOoly0Gvxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dictionary():\n",
        "  def __init__(self, path, size):\n",
        "    self.size = size\n",
        "    self.book = self.build(path, size)\n",
        "    self.listed = self.to_list(path)\n",
        "  \n",
        "  def build(self, path, size):\n",
        "    result = dict()\n",
        "    with open(path) as input:\n",
        "      for line in input:\n",
        "        line = line[:-1]\n",
        "        num = hash(line) % size\n",
        "        if num in result:\n",
        "          result[num].append(line)\n",
        "        else:\n",
        "          result[num] = [line]\n",
        "    return result\n",
        "  \n",
        "  def to_list(self, path):\n",
        "    result = []\n",
        "    with open(path) as input:\n",
        "      for line in input:\n",
        "        result.append(line[:-1])\n",
        "    return result\n",
        "\n",
        "  def get_word(self, word):\n",
        "    num = hash(word) % self.size\n",
        "    return (num in self.book and word in self.book[num])\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ck0725JYObW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Our N-Gram Language Model"
      ],
      "metadata": {
        "id": "SXL7xTibGoqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel():\n",
        "    def __init__(self, n, train_data, alpha=1):\n",
        "        \"\"\"\n",
        "        Language model class.\n",
        "        \n",
        "        Args\n",
        "        ____\n",
        "        n: int\n",
        "            n-gram order\n",
        "        train_data: List[List]\n",
        "            list of words in the dictionary that have not been preprocessed yet\n",
        "        alpha: float\n",
        "            Smoothing parameter\n",
        "        \n",
        "        Other required parameters:\n",
        "            self.vocab: vocabulary dict with counts\n",
        "            self.model: n-gram language model, i.e., n-gram dict with probabilties\n",
        "            self.n_grams_counts: Frequency count for each of the n-grams present in the training data\n",
        "            self.prefix_counts: Frequency count of all the corresponding n-1 grams present in the training data\n",
        "        \"\"\"\n",
        "        self.n = n\n",
        "        self.train_data = train_data\n",
        "        self.tokens = self.train_data\n",
        "        self.n_grams_counts = None\n",
        "        self.prefix_counts = None\n",
        "        self.vocab  = Counter(self.tokens)\n",
        "        self.alpha = alpha\n",
        "        self.model = self.build()\n",
        "\n",
        "    def get_smooth_probabilities(self,n_gram):\n",
        "      vocab_size = len(self.vocab)\n",
        "      ngram_sum = self.n_grams_counts[n_gram]\n",
        "\n",
        "      prefix_sum = len(self.tokens)\n",
        "      if(self.n>1):\n",
        "        prefix_sum = self.prefix_counts[n_gram[0:self.n-1]]\n",
        "        \n",
        "        \n",
        "\n",
        "      return (ngram_sum + self.alpha)/(prefix_sum + self.alpha*vocab_size)\n",
        "\n",
        "\n",
        "      #Returns the smoothed probability of a single ngram, using Laplace Smoothing. Remember to handle the special case of n=1\n",
        "      #Use the class variables we defined in the build function. It is suggested to implement the build function before this one.\n",
        "\n",
        "    \n",
        "    #TODO:\n",
        "    def build(self):\n",
        "        \n",
        "        #Returns a n-gram (could be a unigram) dict with n-gram tuples as keys and probabilities as values. \n",
        "        #It could be a unigram model as well\n",
        "        ngrams = get_ngrams(self.train_data,n=self.n)\n",
        "        prefix_ngrams = get_ngrams(self.train_data,n = self.n-1)\n",
        "\n",
        "        self.n_grams_counts = Counter(ngrams)\n",
        "        self.prefix_counts = Counter(prefix_ngrams)\n",
        "\n",
        "        prob = dict()\n",
        "        for n_gram in self.n_grams_counts:\n",
        "          prob[n_gram] = self.get_smooth_probabilities(n_gram)\n",
        "\n",
        "        return prob"
      ],
      "metadata": {
        "id": "-YS-RbLznc5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Albert: N-Gram Language Model-Based Solver"
      ],
      "metadata": {
        "id": "pqlS4eMWGh8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Albert():\n",
        "  def __init__(self, model,n):\n",
        "    # I want to pass in a naive bayes n-gram model here.\n",
        "    #the probability \"p\" is the parameter we want to train\n",
        "    self.model = model\n",
        "    self.p = 0.03\n",
        "    self.n = n\n",
        "    self.weight = 0.5\n",
        "    self.learning_rate = .05\n",
        "  \n",
        "  def check_probability(self, path, next):\n",
        "    candidate = path[-(self.n-1):] + next\n",
        "    return (candidate in self.model and self.model[candidate] >= self.p)\n",
        "  \n",
        "\n",
        "  def bfs(self, tile, adjlist, board, path, result, visited):\n",
        "    #INPUT\n",
        "    #tile : the root tile that we are starting from\n",
        "    #adjlist : adjacency list of our graph\n",
        "    #board : 2d matrix of our graph so accessing is easier\n",
        "    #path : the current accumulated letters for our words\n",
        "    #pathprob : should we add the log probability of the current path? will do it on second try\n",
        "    #result : the resulting set from the past\n",
        "    #visited : the tiles that we have already visited\n",
        "\n",
        "    #OUTPUT\n",
        "    #result : the resulting set after conducting bfs\n",
        "\n",
        "    #check if current path is a word\n",
        "    if(len(path)>3 and self.check_probability(path, \"\\n\")):\n",
        "      result.add(path + \"\\n\")\n",
        "\n",
        "    #check if extensions are a word\n",
        "    #for each neighbor\n",
        "    for neighbor in adjlist[tile]:\n",
        "        #if we haven't visited it yet, we do smth\n",
        "        #so if we've visited all the neighbors we just move on\n",
        "        if neighbor not in visited:\n",
        "            next = str(board[neighbor[0]][neighbor[1]])\n",
        "            #check probabilities\n",
        "            if(self.check_probability(path, next)):\n",
        "              new = path + next\n",
        "              temp = visited.copy()\n",
        "              temp.append(neighbor)\n",
        "              result = result | self.bfs(neighbor, adjlist, board, new, result, temp)\n",
        "    return result \n",
        "\n",
        "\n",
        "  def solve(self, board):\n",
        "      #INPUT\n",
        "      # board: a 2-d char array of n x n dimensions\n",
        "      # cutoff: the probability 0 < cutoff < 1, such that if the probability a character follows is lower than this cutoff we do not pursue this path\n",
        "\n",
        "      #OUTPUT\n",
        "      # result: a set of words found from the board\n",
        "\n",
        "      result = set()\n",
        "\n",
        "      #first, we want to make an adjacency list\n",
        "      adjlist = board_to_adjlist(board)\n",
        "      for tile in adjlist:\n",
        "        visited = [tile]\n",
        "        path = \"0\" + str(board[tile[0]][tile[1]])\n",
        "        found = self.bfs(tile, adjlist, board,path , set(), visited)\n",
        "        result = result | found\n",
        "         \n",
        "      return post_process(result)\n",
        "  \n",
        "\n",
        "  \n",
        "  def train(self, boards, ref_sol):\n",
        "    board_num = 0\n",
        "    index_coords = []\n",
        "    precision_coords = []\n",
        "    recall_coords = []\n",
        "    p_coords = []\n",
        "    runtime_coords = []\n",
        "    for board in boards:\n",
        "      # print(\"Board number \", board_num)\n",
        "      # print(board)\n",
        "      # this timer will make sure that every board takes less than some amount of time\n",
        "      board = [board]\n",
        "      starttime = time.perf_counter()\n",
        "      metrics = self.evaluate(board, ref_sol)\n",
        "      endtime = time.perf_counter()\n",
        "      runtime = endtime - starttime\n",
        "      # print(\"Time taken: \", runtime)\n",
        "      # bullshit weights tbh but here is where we will evaluate and update\n",
        "      # if recall isn't high enough, then subtract something from the cutoff prob\n",
        "      self.p = self.p - (self.weight)*(1-metrics[0][1])*self.learning_rate\n",
        "      # if time is too high, add something to the cutoff prob (assumption is a tradeoff b/t time and recall)\n",
        "      self.p = self.p + self.learning_rate*runtime\n",
        "      # print(\"New cutoff: \", self.p, \"\\n\")\n",
        "      # append a ton of stuff to a ton of lists for plotting purposes\n",
        "      index_coords.append(board_num)\n",
        "      precision_coords.append(metrics[0][0])\n",
        "      recall_coords.append(metrics[0][1])\n",
        "      p_coords.append(self.p)\n",
        "      runtime_coords.append(runtime)\n",
        "      # increment board number\n",
        "      board_num += 1\n",
        "    # now we are going to plot a bunch of stuff for eval purposes\n",
        "    plt.plot(index_coords, precision_coords)\n",
        "    plt.ylabel(\"precision\")\n",
        "    plt.show()\n",
        "    plt.plot(index_coords, recall_coords)\n",
        "    plt.ylabel(\"recall\")\n",
        "    plt.show()\n",
        "    plt.plot(index_coords, p_coords)\n",
        "    plt.ylabel(\"p values\")\n",
        "    plt.show()\n",
        "    plt.plot(index_coords, runtime_coords)\n",
        "    plt.ylabel(\"runtime\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    #essentially, what we want to do here is solve each board\n",
        "    #its better to make our probability initially really small so that\n",
        "    #runtime isn't dogshit (it will take eons to run if we go through every single possible path)\n",
        "    #then our loss function will be p = p * log (wP/wR) (thinking about adding here, see which one does better), \n",
        "    # where wP is the weighted precision and wR is the weighted recall (this is based on wordhunt scores, eg 800 for 5 letter words)\n",
        "    #we keep going until we go through all the boards and solutions\n",
        "    #afterwards, print our final p-value to see where it ended up\n",
        "    return\n",
        "  \n",
        "\n",
        "  def evaluate(self, boards, ref_sol):\n",
        "    # boards: a list of boards (generated by the helper function generate_random_boards)\n",
        "    # this will contain a a row for every board; each row contains the precision, recall, and f1 of our solution against reference, in that order\n",
        "    summary_stats = []\n",
        "    epoch = 0\n",
        "    for board in boards:\n",
        "      reference = ref_sol.solve(board)\n",
        "      train_sol = self.solve(board)\n",
        "      # find precision, recall\n",
        "      prec = precision(train_sol, reference)\n",
        "      rec = recall(train_sol, reference)\n",
        "      f1 = 0\n",
        "      if(prec + rec != 0):\n",
        "        f1 = (prec * rec)/(prec + rec)\n",
        "      # print(\"Precision: \", prec, \"Recall: \", rec, \"F1\", f1, \"Cutoff prob: \", self.p)\n",
        "      summary_stats.append([prec, rec, f1])\n",
        "    return summary_stats"
      ],
      "metadata": {
        "id": "o_UOthuAT3C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possible Cross-Entropy Loss Function:\n",
        "\n",
        "Loss = -1/(output size) * Σ_(from 1 ~ output size) (x_i * log xhat_i) + ((1-x_i) * log (1-xhat_i))\n",
        "\n",
        "ideally if we wanna take time into account, we should add a penalty term to Loss Function that is proportional to Time Elapsed (e.g. maybe log?? MSE), where it is MSE between predicted (based on ngram length?) - true elapsed time"
      ],
      "metadata": {
        "id": "wQrvi6fVcHIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alexei: Albert 2.0\n",
        "Alexei is also a n-gram based, model, but this time we will look at overall path probability, rather than localized n-gram probability."
      ],
      "metadata": {
        "id": "DFo04kN2b34V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "05m7D4hVcFQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h01szF_jcEjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Alexei():\n",
        "  def __init__(self, path , n, size, beta, alpha):\n",
        "    # I want to pass in a naive bayes n-gram model here.\n",
        "    #the probability \"p\" is the parameter we want to train\n",
        "    lm = LanguageModel(n, path)\n",
        "    dictionary = Dictionary(path, size)\n",
        "    self.model = lm.model\n",
        "    self.beta = beta\n",
        "    self.alpha = alpha\n",
        "    self.p = self.find_cutoffs(dictionary.listed)\n",
        "    self.p[16] = -30\n",
        "    self.n = n\n",
        "    \n",
        "  \n",
        "  def calculate_logprob(self, word, n):\n",
        "    word = \"0\" + word + \"\\n\"\n",
        "    result = 0\n",
        "    for i in range(len(word) - (n-1)):\n",
        "      result += math.log(self.model[word[i:i+n]])\n",
        "    return result\n",
        "  \n",
        "  def eq(self, x, alpha, beta):\n",
        "    exponent = -((1/math.log(x))*(x-10))\n",
        "    coefficient = (0.5 - 1/(1 + math.exp(exponent)))\n",
        "    return beta + alpha*coefficient\n",
        "  \n",
        "  def find_cutoffs(self, dictionary):\n",
        "    temp = dict()\n",
        "    result = dict()\n",
        "    for word in dictionary:\n",
        "      if (len(word) in temp):\n",
        "        temp[len(word)].append(self.calculate_logprob(word, 3))\n",
        "      else:\n",
        "        temp[len(word)] = [self.calculate_logprob(word, 3)]\n",
        "    for length,probabilities in temp.items():\n",
        "        result[length] = statistics.mean(probabilities) - (self.eq(length, self.alpha, self.beta))*statistics.stdev(probabilities)\n",
        "        #print(\"length: {}, mean: {:.3f}, std: {:.3f}\".format(length, statistics.mean(probabilities), statistics.stdev(probabilities)))\n",
        "    return result\n",
        "  \n",
        "  def check_probability(self, path, pathprob, next):\n",
        "    length = len(path)\n",
        "    #if(length == 16):\n",
        "    #  print(path)\n",
        "    candidate = path[-(self.n-1):] + next\n",
        "    \n",
        "    if (candidate in self.model):\n",
        "      nextprob = math.log(self.model[candidate])\n",
        "      if (length == 2 or pathprob + nextprob >= self.p[length-1]):\n",
        "        return nextprob\n",
        "    return 0\n",
        "  \n",
        "\n",
        "  def bfs(self, tile, adjlist, board, path, pathprob, result, visited):\n",
        "    #INPUT\n",
        "    #tile : the root tile that we are starting from\n",
        "    #adjlist : adjacency list of our graph\n",
        "    #board : 2d matrix of our graph so accessing is easier\n",
        "    #path : the current accumulated letters for our words\n",
        "    #pathprob : should we add the log probability of the current path? will do it on second try\n",
        "    #result : the resulting set from the past\n",
        "    #visited : the tiles that we have already visited\n",
        "\n",
        "    #OUTPUT\n",
        "    #result : the resulting set after conducting bfs\n",
        "\n",
        "    #check if current path is a word\n",
        "    if(len(path)>3 and self.check_probability(path, pathprob,\"\\n\")):\n",
        "      result.add(path + \"\\n\")\n",
        "\n",
        "    #check if extensions are a word\n",
        "    #for each neighbor\n",
        "    for neighbor in adjlist[tile]:\n",
        "        #if we haven't visited it yet, we do smth\n",
        "        #so if we've visited all the neighbors we just move on\n",
        "        if neighbor not in visited:\n",
        "            next = str(board[neighbor[0]][neighbor[1]])\n",
        "            #check probabilities\n",
        "            nextprob = self.check_probability(path, pathprob, next)\n",
        "            if(nextprob):\n",
        "              new = path + next\n",
        "              temp = visited.copy()\n",
        "              temp.append(neighbor)\n",
        "              result = result | self.bfs(neighbor, adjlist, board, new, pathprob + nextprob, result, temp)\n",
        "    return result \n",
        "\n",
        "\n",
        "  def solve(self, board):\n",
        "      #INPUT\n",
        "      # board: a 2-d char array of n x n dimensions\n",
        "      # cutoff: the probability 0 < cutoff < 1, such that if the probability a character follows is lower than this cutoff we do not pursue this path\n",
        "\n",
        "      #OUTPUT\n",
        "      # result: a set of words found from the board\n",
        "\n",
        "      result = set()\n",
        "\n",
        "      #first, we want to make an adjacency list\n",
        "      adjlist = board_to_adjlist(board)\n",
        "      for tile in adjlist:\n",
        "        visited = [tile]\n",
        "        path = \"0\" + str(board[tile[0]][tile[1]])\n",
        "        found = self.bfs(tile, adjlist, board, path , 0, set(), visited)\n",
        "        result = result | found\n",
        "         \n",
        "      return post_process(result)\n",
        "  \n",
        "  def train(self, boards, solutions):\n",
        "    #essentially, what we want to do here is solve each board\n",
        "    #its better to make our probability initially really small so that\n",
        "    #runtime isn't dogshit (it will take eons to run if we go through every single possible path)\n",
        "    #then our loss function will be p = p * log (wP/wR) (thinking about adding here, see which one does better), \n",
        "    # where wP is the weighted precision and wR is the weighted recall (this is based on wordhunt scores, eg 800 for 5 letter words)\n",
        "    #we keep going until we go through all the boards and solutions\n",
        "    #afterwards, print our final p-value to see where it ended up\n",
        "    for board in boards:\n",
        "      candidate_sol = self.solve(board)\n",
        "      prec = self.precision()\n",
        "    return\n",
        "  \n",
        "\n",
        "  def evaluate(self, boards):\n",
        "    # boards: a list of boards (generated by the helper function generate_random_boards)\n",
        "    # this will contain a a row for every board; each row contains the precision, recall, and f1 of our solution against reference, in that order\n",
        "    summary_stats = []\n",
        "    epoch = 0\n",
        "    for board in boards:\n",
        "      print(board)\n",
        "      print(\"epoch\", epoch, \":\\n\")\n",
        "      # TODO: FIX THE SYNTAX (ref_sol.solve is 100% not correct)\n",
        "      ref_sol = ref_sol.solve(board)\n",
        "      train_sol = self.solve(board)\n",
        "      # find precision, recall\n",
        "      prec = self.precision(train_sol, ref_sol)\n",
        "      rec = self.recall(train_sol, ref_sol)\n",
        "      f1 = (prec * rec)/(prec + rec)\n",
        "      print(\"Precision: \", prec, \"Recall: \", rec, \"F1\", f1)\n",
        "      summary_stats.append([prec, rec, f1])\n",
        "    return summary_stats"
      ],
      "metadata": {
        "id": "hMmQaY4Cb9i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Isaac: Dictionary-Based Solver"
      ],
      "metadata": {
        "id": "vSblfq6cGcR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Isaac():\n",
        "  def __init__(self, dictionary):\n",
        "    self.dictionary = dictionary.listed\n",
        "  \n",
        "\n",
        "  def dfs(self, word, tile, adjlist, visited, path, board):\n",
        "    if(path == len(word)):\n",
        "      return True\n",
        "    \n",
        "    for neighbor in adjlist[tile]:\n",
        "      if neighbor not in visited:\n",
        "        if board[neighbor[0]][neighbor[1]] == word[path]:\n",
        "          temp = visited.copy()\n",
        "          temp.append(neighbor)\n",
        "          if(self.dfs(word,neighbor, adjlist, temp, path + 1, board)):\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "  def solve(self, board):\n",
        "    result = []\n",
        "    adjlist = board_to_adjlist(board)\n",
        "    lst = board_to_list(board)\n",
        "    ref = board_to_dict(board)\n",
        "    #im going to make a dictionary for easy access\n",
        "\n",
        "    for word in self.dictionary:\n",
        "      if len(word) > 2 and len(word) <= 16 and exists(word, lst):\n",
        "        for start in ref[word[0]]:\n",
        "          if(self.dfs(word, start, adjlist, [start], 1, board)):\n",
        "            result.append(word)\n",
        "            break\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "evQruf96TK1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Begins!"
      ],
      "metadata": {
        "id": "RRKSl8a9GWbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tester = [['A','N','T','E'], ['E','T','A','A'], ['R','D','N','N'], ['L','L','E','K']]"
      ],
      "metadata": {
        "id": "mjlDHyzbVki1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = Dictionary(\"dictionary.txt\",10000)"
      ],
      "metadata": {
        "id": "Rz-8XChF-zAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = LanguageModel(3, \"dictionary.txt\")\n",
        "albert = Albert(lm.model, 3)"
      ],
      "metadata": {
        "id": "t4CxuO3kSQud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tic = time.perf_counter()\n",
        "result = albert.solve(tester)\n",
        "result = sorted(result, key = len, reverse = True)\n",
        "print(len(result))\n",
        "result = validate(dictionary, result)\n",
        "toc = time.perf_counter()\n",
        "print(toc - tic)\n",
        "result = sorted(result, key = len, reverse = True)\n",
        "print(result)\n",
        "print(len(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZlroFIi8_dP",
        "outputId": "73ec9210-3fbd-472a-942b-96ea1f97e987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8606\n",
            "0.8046062280000115\n",
            "['ANDANTE', 'TANNATE', 'DENTATE', 'ENTENTE', 'TANNED', 'LENDER', 'LENTEN', 'NATTER', 'NATANT', 'REATA', 'ANTED', 'TATER', 'EATER', 'ENDER', 'DATER', 'ENATE', 'ENTER', 'EATEN', 'ANTRE', 'KENTE', 'RENTE', 'RENT', 'DEAN', 'DELL', 'TENT', 'REDE', 'LENT', 'KENT', 'DATA', 'TATE', 'ANTE', 'ANTA', 'DATE', 'DENT', 'ANNA', 'LEND', 'NANA', 'NAN', 'ANE', 'ELL', 'KEN', 'TED', 'DAN', 'RET', 'ETA', 'TEN', 'ANT', 'AND', 'LED', 'ANA', 'DEL', 'DEN', 'ATE', 'TAN', 'RED', 'NET', 'END']\n",
            "57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alexei = Alexei(\"dictionary.txt\", 3,10000, 0.3, 0.3)"
      ],
      "metadata": {
        "id": "DB1i-3pNe2Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tic = time.perf_counter()\n",
        "result = alexei.solve(tester)\n",
        "result = sorted(result, key = len, reverse = True)\n",
        "print(len(result))\n",
        "result = validate(dictionary, result)\n",
        "toc = time.perf_counter()\n",
        "print(toc - tic)\n",
        "result = sorted(result, key = len, reverse = True)\n",
        "print(result)\n",
        "print(len(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9u5Bl-PfEvr",
        "outputId": "874162a8-da43-4837-cf08-3676c172d678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3290\n",
            "0.22196086899930378\n",
            "['ANTEATER', 'ANTEDATE', 'ANDANTE', 'TANNATE', 'DENTATE', 'ENTENTE', 'REDATE', 'LENDER', 'LENTEN', 'TANKED', 'TANNED', 'NATTER', 'NATANT', 'TEATED', 'ENTER', 'REATA', 'ELDER', 'ANTED', 'TATER', 'EATEN', 'ANTRE', 'EATER', 'ENDER', 'KNELL', 'DATER', 'ANENT', 'KENTE', 'ENATE', 'RENTE', 'REDAN', 'ANTAE', 'RENT', 'DEAN', 'KENT', 'TATE', 'ANTE', 'ANTA', 'DATE', 'NERD', 'DELL', 'DANK', 'DENT', 'TANK', 'ANNA', 'TENT', 'REDE', 'LEND', 'LENT', 'NAN', 'TAT', 'ANE', 'ELL', 'KEN', 'NAE', 'TED', 'DAN', 'DEN', 'RET', 'ETA', 'ATE', 'TEN', 'ELD', 'TAD', 'TAN', 'ANT', 'EAT', 'AND', 'LED', 'ANA', 'RED', 'NET', 'END', 'DEL']\n",
            "73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "isaac = Isaac(dictionary)"
      ],
      "metadata": {
        "id": "8y-59NsNSW2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boards = generate_random_boards(500, 4,4)\n",
        "#print(boards)\n",
        "#albert.train(boards, isaac)\n",
        "# print(albert.p)"
      ],
      "metadata": {
        "id": "1StkdjqxORfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tic = time.perf_counter()\n",
        "result = isaac.solve(tester)\n",
        "result = sorted(result, key = len, reverse = True)\n",
        "print(len(result))\n",
        "result = validate(dictionary, result)\n",
        "toc = time.perf_counter()\n",
        "print(toc - tic)\n",
        "result = sorted(result, key = len, reverse = True)\n",
        "print(result)\n",
        "print(len(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuGsQtga6NvA",
        "outputId": "78c871b7-ff8d-4601-82f2-e555dd008531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87\n",
            "0.4502996749997692\n",
            "['ANTEATER', 'ANTEDATE', 'EDENTATE', 'ANDANTE', 'DENTATE', 'ENTENTE', 'TANNATE', 'ADNATE', 'ANANKE', 'LENDER', 'LENTEN', 'NATANT', 'NATTER', 'REDATE', 'TANKED', 'TANNED', 'TEATED', 'ANENT', 'ANTAE', 'ANTED', 'ANTRE', 'DATER', 'EATEN', 'EATER', 'ELDER', 'ENATE', 'ENDER', 'ENTER', 'KENTE', 'KNELL', 'REATA', 'REDAN', 'RENTE', 'TATER', 'ANNA', 'ANTA', 'ANTE', 'DANK', 'DATA', 'DATE', 'DEAN', 'DELL', 'DENT', 'ETNA', 'KENT', 'LEND', 'LENT', 'NAAN', 'NANA', 'NEAT', 'NERD', 'NETT', 'REDE', 'RENT', 'TANK', 'TATE', 'TEAT', 'TENT', 'ANA', 'AND', 'ANE', 'ANT', 'ATE', 'ATT', 'DAN', 'DEL', 'DEN', 'EAT', 'ELD', 'ELL', 'END', 'ETA', 'KEN', 'LED', 'LEK', 'NAE', 'NAN', 'NET', 'RED', 'RET', 'TAD', 'TAE', 'TAN', 'TAT', 'TEA', 'TED', 'TEN']\n",
            "87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MASS TESTING\n",
        "The idea here is we're going to generate a bunch of random boards and solve each one. We will first evaluate on a few easy metrics that we have already looked at previously\n",
        "\n",
        "\n",
        "1.   Number Correct/Number Total\n",
        "2.   Number Correct/Number Generated\n",
        "3.   Time to Generate\n",
        "\n"
      ],
      "metadata": {
        "id": "RAv2cEfyhrax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_score(wordlist):\n",
        "  score = 0\n",
        "  for word in wordlist:\n",
        "    length = len(word)\n",
        "    if (length == 3):\n",
        "      score += 100\n",
        "    elif (length == 4):\n",
        "      score += 400\n",
        "    elif (length == 5):\n",
        "      score += 800\n",
        "    elif (length == 6):\n",
        "      score += 1400\n",
        "    else:\n",
        "      score += 1400 + 400*(length - 6) \n",
        "  return score"
      ],
      "metadata": {
        "id": "_g4SUq_jqK4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def words_per_length(saved, input):\n",
        "  for item in input:\n",
        "    saved[len(item)] +=1 \n",
        "  return saved"
      ],
      "metadata": {
        "id": "qYCkExKaBHd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(batch, n):\n",
        "  #summary statistics of albert\n",
        "  albert_precision = 0\n",
        "  albert_acc = 0\n",
        "  albert_time = 0\n",
        "  albert_score = 0\n",
        "  #summary statistics of alexei\n",
        "  alexei_precision = 0\n",
        "  alexei_acc = 0\n",
        "  alexei_time = 0\n",
        "  alexei_score = 0\n",
        "  #summary statistics of isaac\n",
        "  isaac_precision = 1\n",
        "  isaac_acc = 1\n",
        "  isaac_time = 0 \n",
        "  isaac_score = 0\n",
        "  generated = defaultdict(lambda: 0)\n",
        "  for board in batch:\n",
        "    \n",
        "    #TESTING FOR ISAAC - OUR CONTROL SOLUTION\n",
        "    tic = time.perf_counter()\n",
        "    isaac_res = isaac.solve(board)\n",
        "    toc = time.perf_counter()\n",
        "    isaac_time += (toc - tic)\n",
        "    isaac_score += get_score(isaac_res)\n",
        "    refsol = len(isaac_res)\n",
        "\n",
        "    \n",
        "    #TESTING FOR ALBERT - OUR FIRST VERSION\n",
        "    tic = time.perf_counter()\n",
        "    albert_res = albert.solve(board)\n",
        "    tot_albert = len(albert_res)\n",
        "    albert_res = validate(dictionary, albert_res)\n",
        "    red_albert = len(albert_res)\n",
        "    toc = time.perf_counter()\n",
        "    albert_time += (toc - tic)\n",
        "    albert_precision += red_albert/tot_albert\n",
        "    albert_acc += red_albert/refsol\n",
        "    albert_score += get_score(albert_res)\n",
        "    \n",
        "\n",
        "    #TESTING FOR ALEXEI - OUR SECOND VERSION\n",
        "    tic = time.perf_counter()\n",
        "    alexei_res = alexei.solve(board)\n",
        "    tot_alexei = len(alexei_res)\n",
        "    #print(tot_alexei)\n",
        "    generated = words_per_length(generated, alexei_res)\n",
        "    alexei_res = validate(dictionary, alexei_res)\n",
        "    red_alexei = len(alexei_res)\n",
        "    toc = time.perf_counter()\n",
        "    alexei_time += (toc - tic)\n",
        "    alexei_precision += red_alexei/tot_alexei\n",
        "    alexei_acc += red_alexei/refsol\n",
        "    alexei_score += get_score(alexei_res)\n",
        "  \n",
        "  #printing the final statistics\n",
        "  print(\"FINAL SUMMARY STATISTICS\")\n",
        "  print(\"########################\")\n",
        "  print(\"ISAAC REFERENCE STATISTICS\")\n",
        "  print(\"ISAAC NUMBER CORRECT/NUMBER TOTAL: {}\".format(isaac_precision))\n",
        "  print(\"ISAAC NUMBER CORRECT/NUMBER GENERATED: {}\".format(isaac_acc))\n",
        "  print(\"ISAAC AVERAGE SCORE: {}\".format(isaac_score/n))\n",
        "  print(\"ISAAC AVERAGE TIME TO SOLVE: {}\".format(isaac_time/n))\n",
        "  print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "  print(\"ALBERT REFERENCE STATISTICS\")\n",
        "  print(\"ALBERT NUMBER CORRECT/NUMBER TOTAL: {}\".format(albert_precision/n))\n",
        "  print(\"ALBERT NUMBER CORRECT/NUMBER GENERATED: {}\".format(albert_acc/n))\n",
        "  print(\"ALBERT AVERAGE SCORE: {}\".format(albert_score/n))\n",
        "  print(\"ALBERT AVERAGE TIME TO SOLVE: {}\".format(albert_time/n))\n",
        "  print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "  \n",
        "  print(\"ALEXEI REFERENCE STATISTICS\")\n",
        "  print(\"ALEXEI NUMBER CORRECT/NUMBER TOTAL: {}\".format(alexei_precision/n))\n",
        "  print(\"ALEXEI NUMBER CORRECT/NUMBER GENERATED: {}\".format(alexei_acc/n))\n",
        "  print(\"ALEXEI AVERAGE SCORE: {}\".format(alexei_score/n))\n",
        "  print(\"ALEXEI AVERAGE TIME TO SOLVE: {}\".format(alexei_time/n))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gspg4MZbiTv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexei_stats_rt = dict()\n",
        "alexei_stats_rc = dict()\n",
        "batch = generate_random_boards(500,4,4)\n",
        "alexei = Alexei(\"dictionary.txt\", 3,10000,0,2.5)\n",
        "\n",
        "test(batch, 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkU1aoklk2H9",
        "outputId": "df07dd29-6aa8-4376-e39e-637f71e0080a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL SUMMARY STATISTICS\n",
            "########################\n",
            "ISAAC REFERENCE STATISTICS\n",
            "ISAAC NUMBER CORRECT/NUMBER TOTAL: 1\n",
            "ISAAC NUMBER CORRECT/NUMBER GENERATED: 1\n",
            "ISAAC AVERAGE SCORE: 58540.4\n",
            "ISAAC AVERAGE TIME TO SOLVE: 0.39300642685399273\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ALBERT REFERENCE STATISTICS\n",
            "ALBERT NUMBER CORRECT/NUMBER TOTAL: 0.06457007462791858\n",
            "ALBERT NUMBER CORRECT/NUMBER GENERATED: 0.4600438647501498\n",
            "ALBERT AVERAGE SCORE: 28470.0\n",
            "ALBERT AVERAGE TIME TO SOLVE: 0.14499557370596175\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ALEXEI REFERENCE STATISTICS\n",
            "ALEXEI NUMBER CORRECT/NUMBER TOTAL: 0.05925576608238614\n",
            "ALEXEI NUMBER CORRECT/NUMBER GENERATED: 0.8992711506589818\n",
            "ALEXEI AVERAGE SCORE: 51621.4\n",
            "ALEXEI AVERAGE TIME TO SOLVE: 0.1336811253220094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def distribution_test(n):\n",
        "  isaacdist = defaultdict(lambda: 0)\n",
        "  albertdist = defaultdict(lambda: 0)\n",
        "  alexeidist = defaultdict(lambda: 0)\n",
        "  total = 0\n",
        "\n",
        "  batch = generate_random_boards(n,4,4)\n",
        "  for board in batch:\n",
        "    refsol = isaac.solve(board)\n",
        "    albertsol = albert.solve(board)\n",
        "    albertsol = validate(dictionary, albertsol)\n",
        "    alexeisol = alexei.solve(board)\n",
        "    alexeisol = validate(dictionary, alexeisol)\n",
        "    #getting distribution for the solutions\n",
        "    for i in range(len(refsol)):\n",
        "      isaacdist[len(refsol[i])] += 1\n",
        "      total += 1\n",
        "    #getting distributions for albert\n",
        "    for i in range(len(albertsol)):\n",
        "      albertdist[len(albertsol[i])] += 1\n",
        "    #getting distributions for alexei    \n",
        "    for i in range(len(alexeisol)):\n",
        "      alexeidist[len(alexeisol[i])] += 1\n",
        "  \n",
        "  print(\"DISTRIBUTION STATISTICS\")\n",
        "  print(\"#######################\")\n",
        "  for length, found in isaacdist.items():\n",
        "    albertpercent = albertdist[length]/found\n",
        "    alexeipercent = alexeidist[length]/found\n",
        "    totaldist = found/total\n",
        "    print(\"OF LENGTH {}: ALBERT - {}%\\tALEXEI - {}%\\tTOTAL DISTRIBUTION -  {}%\".format(length, albertpercent, alexeipercent, totaldist))\n"
      ],
      "metadata": {
        "id": "bTwNRTnZNH1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distribution_test(500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEg3eo_wSdL-",
        "outputId": "c11407ca-68e3-4ab2-b7a4-4073eab0ba28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DISTRIBUTION STATISTICS\n",
            "#######################\n",
            "OF LENGTH 3: ALBERT - 0.4496613535672455%\tALEXEI - 0.8932117940622295%\tTOTAL DISTRIBUTION -  0.32927544980465145%\n",
            "OF LENGTH 4: ALBERT - 0.4875052352366327%\tALEXEI - 0.8652333752152264%\tTOTAL DISTRIBUTION -  0.3603299964786961%\n",
            "OF LENGTH 5: ALBERT - 0.5096955264500765%\tALEXEI - 0.8522707943527811%\tTOTAL DISTRIBUTION -  0.1971594815299227%\n",
            "OF LENGTH 6: ALBERT - 0.4896341463414634%\tALEXEI - 0.8443089430894309%\tTOTAL DISTRIBUTION -  0.08249911967402787%\n",
            "OF LENGTH 7: ALBERT - 0.460231135282121%\tALEXEI - 0.8477226376614548%\tTOTAL DISTRIBUTION -  0.02466589533343394%\n",
            "OF LENGTH 8: ALBERT - 0.43670886075949367%\tALEXEI - 0.810126582278481%\tTOTAL DISTRIBUTION -  0.0052987239465432535%\n",
            "OF LENGTH 10: ALBERT - 0.6666666666666666%\tALEXEI - 0.6666666666666666%\tTOTAL DISTRIBUTION -  0.00010060868252930228%\n",
            "OF LENGTH 9: ALBERT - 0.35%\tALEXEI - 0.775%\tTOTAL DISTRIBUTION -  0.0006707245501953485%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Distributions"
      ],
      "metadata": {
        "id": "bfVImA_dmW8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I explore the relationship between probability and word length here."
      ],
      "metadata": {
        "id": "5P4lUbuwhbrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "#idk what this is but im gonna try it\n",
        "def calculate_logprob(word, n):\n",
        "  word = \"0\" + word + \"\\n\"\n",
        "  result = 0\n",
        "  for i in range(len(word) - (n-1)):\n",
        "    if(word[i:i+n] in lm.model):\n",
        "      result += math.log(lm.model[word[i:i+n]])\n",
        "  return result\n",
        "\n",
        "temp = defaultdict(lambda: list())\n",
        "result = dict()\n",
        "for word in dictionary.listed:\n",
        "  if (len(word) > 4):\n",
        "    temp[len(word)].append(calculate_logprob(word[:5], 3))\n",
        "\n",
        "for length,probabilities in temp.items():\n",
        "    result[length] = sum(probabilities)/len(probabilities)\n",
        "baseline = result[5]\n",
        "for length, probabilities in temp.items():\n",
        "    data = np.array(probabilities)\n",
        "    normalized = (np.average(probabilities) - baseline)/(np.std(probabilities))\n",
        "    print(normalized)\n",
        "    result[length] = normalized\n",
        "    \n",
        "print(result)\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEbnyPOWICSv",
        "outputId": "17910d7d-4580-45a4-851b-d552e381c12f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.9076665321879158e-14\n",
            "-0.4070092510348233\n",
            "-0.40128288293674175\n",
            "-0.28599092893476197\n",
            "-0.19768034901877352\n",
            "-0.5737234292063061\n",
            "-0.14560630539897973\n",
            "-0.03961992469762816\n",
            "-0.005064031017177949\n",
            "0.02230557732163934\n",
            "0.05786176244881148\n",
            "{5: -1.9076665321879158e-14, 6: -0.4070092510348233, 8: -0.40128288293674175, 9: -0.28599092893476197, 10: -0.19768034901877352, 7: -0.5737234292063061, 11: -0.14560630539897973, 12: -0.03961992469762816, 13: -0.005064031017177949, 14: 0.02230557732163934, 15: 0.05786176244881148}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "lists = sorted(result.items()) # sorted by key, return a list of tuples\n",
        "\n",
        "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ENF6xVL9LisP",
        "outputId": "77afdd49-bfe7-4b78-f98e-479b0dac90de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}