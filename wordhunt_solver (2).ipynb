{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su3zW5IEm3P2"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from itertools import product\n",
        "import math\n",
        "import io\n",
        "import os\n",
        "import time\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PREPROCESSING\n",
        "def get_ngrams(path, n):\n",
        "  result = []\n",
        "  with open(path) as input:\n",
        "    for line in input:\n",
        "      if(len(line)<3 or len(line)>16):\n",
        "        continue\n",
        "      line = \"0\" + line\n",
        "      for i in range(len(line) - (n-1)):\n",
        "        result.append((line[i:i+n]))\n",
        "  return result\n",
        "\n",
        "get_ngrams(\"tester.txt\", 3)\n",
        "\n",
        "\n",
        "def post_process(input):\n",
        "  result = []\n",
        "  for value in input:\n",
        "    result.append(value[1:-1])\n",
        "  return result"
      ],
      "metadata": {
        "id": "ZUTujwufng2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#HELPER FUNCTIONS\n",
        "\n",
        "#turns a 2d matrix into an adjacency list of indeces\n",
        "def board_to_adjlist(board):\n",
        "    result = dict()\n",
        "    for i in range(len(board)):\n",
        "        for j in range(len(board[0])):\n",
        "            idx = (i,j)\n",
        "            neighbors = []\n",
        "            for x in range(-1,2):\n",
        "                for y in range(-1,2):\n",
        "                    if(not(x == 0 and y ==0)):\n",
        "                        if(x + i >=0 and y + j >=0 and x + i < len(board) and y + j < len(board[0])):\n",
        "                            neighbors.append((i+x,j+y))\n",
        "            result[idx] = neighbors\n",
        "    return result\n",
        "\n",
        "#turns a 2d matrix into a list of characters\n",
        "def board_to_list(board):\n",
        "  result = []\n",
        "  for row in board:\n",
        "    result = result + row\n",
        "  result.sort()\n",
        "  return result\n",
        "\n",
        "def board_to_dict(board):\n",
        "  result = dict()\n",
        "  for i in range(len(board)):\n",
        "    for j in range(len(board[0])):\n",
        "      if(board[i][j] not in result):\n",
        "        result[board[i][j]] = [(i,j)]\n",
        "      else:\n",
        "        result[board[i][j]].append((i,j))\n",
        "  return result\n",
        "\n",
        "def exists(word, chars):\n",
        "  #REQUIRES: char is sorted\n",
        "  word = list(word)\n",
        "  word.sort()\n",
        "  curr = 0\n",
        "  i = 0\n",
        "  length = len(chars)\n",
        "  goal = len(word)\n",
        "  while(i < length):\n",
        "    if(curr == goal):\n",
        "      return True\n",
        "    if(word[curr] == chars[i]):\n",
        "      curr +=1\n",
        "    elif(word[curr] < chars[i]):\n",
        "      return False\n",
        "    i +=1\n",
        "  return curr == goal \n",
        "\n",
        "def validate(dictionary, result):\n",
        "  res = []\n",
        "  for word in result:\n",
        "    if(dictionary.get_word(word)):\n",
        "      res.append(word)\n",
        "  return res \n",
        "\n",
        "## CODE FOR TESTING ##\n",
        "\n",
        "# prepares the dict of letters to scrabble freqs that we use in the next function\n",
        "def generate_scrabble_freqs():\n",
        "  scrabble_freqs = {\n",
        "      'e': 12.49,\n",
        "      't':  9.28,\n",
        "      'a':  8.04,\n",
        "      'o':  7.64,\n",
        "      'i':  7.57,\n",
        "      'n':  7.23,\n",
        "      's':  6.51,\n",
        "      'r':  6.28,\n",
        "      'h':  5.05,\n",
        "      'l':  4.07,\n",
        "      'd':  3.82,\n",
        "      'c':  3.34,\n",
        "      'u':  2.73,\n",
        "      'm':  2.51,\n",
        "      'f':  2.40,\n",
        "      'p':  2.14,\n",
        "      'g':  1.87,\n",
        "      'w':  1.68,\n",
        "      'y':  1.66,\n",
        "      'b':  1.48,\n",
        "      'v':  1.05,\n",
        "      'k':  0.54,\n",
        "      'x':  0.23,\n",
        "      'j':  0.16,\n",
        "      'q':  0.12,\n",
        "      'z':  0.09\n",
        "  }\n",
        "  scrabble_freqs = dict(sorted(scrabble_freqs.items(), key=lambda x:x[1]))\n",
        "  index = -1\n",
        "  preventry = \"\"\n",
        "  for entry in scrabble_freqs:\n",
        "    scrabble_freqs[entry[0]] = round(scrabble_freqs[entry[0]] * 100)\n",
        "    # if the previous entry exists, add it to the current entry\n",
        "    if(index >= 0):\n",
        "      scrabble_freqs[entry[0]] = scrabble_freqs[entry[0]] + scrabble_freqs[preventry]\n",
        "    index += 1\n",
        "    preventry = entry[0]\n",
        "  return scrabble_freqs\n",
        "\n",
        "#generates number_of_boards boards with dimensions x by y\n",
        "def generate_random_boards(number_of_boards, x, y):\n",
        "  letter_freqs = generate_scrabble_freqs()\n",
        "  boards = []\n",
        "  for i in range(number_of_boards):\n",
        "    boards.append([[0]*y for i in range(x)])\n",
        "    # fill up the board w/random letters\n",
        "    for j in range(x):\n",
        "      for k in range(y):\n",
        "        # generate random letter\n",
        "        seed = random.randint(0,9998)\n",
        "        letter = ''\n",
        "        for l in letter_freqs:\n",
        "          if(seed <= letter_freqs[l]):\n",
        "            letter = l\n",
        "            break\n",
        "        assert(letter != '')\n",
        "        boards[i][j][k] = letter.upper()\n",
        "  return boards\n",
        "\n",
        "def precision(sols, ref_sols):\n",
        "  prec = 0\n",
        "  for word in sols:\n",
        "    if(word in ref_sols):\n",
        "      prec += 1\n",
        "  return prec/len(sols)\n",
        "\n",
        "def recall(sols, ref_sols):\n",
        "  rec = 0\n",
        "  for word in ref_sols:\n",
        "    if(word in sols):\n",
        "      rec += 1\n",
        "  return rec/len(ref_sols)"
      ],
      "metadata": {
        "id": "f6In1_lC07Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_random_boards(2,4,4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2SbTi9gmExW",
        "outputId": "e7f36b7a-fc01-482b-d8b2-ecc596ba4567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['D', 'C', 'H', 'E'],\n",
              "  ['S', 'N', 'N', 'A'],\n",
              "  ['T', 'T', 'C', 'I'],\n",
              "  ['D', 'R', 'H', 'D']],\n",
              " [['L', 'U', 'N', 'R'],\n",
              "  ['T', 'A', 'C', 'W'],\n",
              "  ['T', 'T', 'T', 'T'],\n",
              "  ['T', 'O', 'I', 'L']]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Literal Hash Dictionary"
      ],
      "metadata": {
        "id": "J0OOoly0Gvxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dictionary():\n",
        "  def __init__(self, path, size):\n",
        "    self.size = size\n",
        "    self.book = self.build(path, size)\n",
        "    self.listed = self.to_list(path)\n",
        "  \n",
        "  def build(self, path, size):\n",
        "    result = dict()\n",
        "    with open(path) as input:\n",
        "      for line in input:\n",
        "        line = line[:-1]\n",
        "        num = hash(line) % size\n",
        "        if num in result:\n",
        "          result[num].append(line)\n",
        "        else:\n",
        "          result[num] = [line]\n",
        "    return result\n",
        "  \n",
        "  def to_list(self, path):\n",
        "    result = []\n",
        "    with open(path) as input:\n",
        "      for line in input:\n",
        "        result.append(line[:-1])\n",
        "    return result\n",
        "\n",
        "  def get_word(self, word):\n",
        "    num = hash(word) % self.size\n",
        "    return (num in self.book and word in self.book[num])\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ck0725JYObW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Our N-Gram Language Model"
      ],
      "metadata": {
        "id": "SXL7xTibGoqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel():\n",
        "    def __init__(self, n, train_data, alpha=1):\n",
        "        \"\"\"\n",
        "        Language model class.\n",
        "        \n",
        "        Args\n",
        "        ____\n",
        "        n: int\n",
        "            n-gram order\n",
        "        train_data: List[List]\n",
        "            list of words in the dictionary that have not been preprocessed yet\n",
        "        alpha: float\n",
        "            Smoothing parameter\n",
        "        \n",
        "        Other required parameters:\n",
        "            self.vocab: vocabulary dict with counts\n",
        "            self.model: n-gram language model, i.e., n-gram dict with probabilties\n",
        "            self.n_grams_counts: Frequency count for each of the n-grams present in the training data\n",
        "            self.prefix_counts: Frequency count of all the corresponding n-1 grams present in the training data\n",
        "        \"\"\"\n",
        "        self.n = n\n",
        "        self.train_data = train_data\n",
        "        self.tokens = self.train_data\n",
        "        self.n_grams_counts = None\n",
        "        self.prefix_counts = None\n",
        "        self.vocab  = Counter(self.tokens)\n",
        "        self.alpha = alpha\n",
        "        self.model = self.build()\n",
        "\n",
        "    def get_smooth_probabilities(self,n_gram):\n",
        "      vocab_size = len(self.vocab)\n",
        "      ngram_sum = self.n_grams_counts[n_gram]\n",
        "\n",
        "      prefix_sum = len(self.tokens)\n",
        "      if(self.n>1):\n",
        "        prefix_sum = self.prefix_counts[n_gram[0:self.n-1]]\n",
        "        \n",
        "        \n",
        "\n",
        "      return (ngram_sum + self.alpha)/(prefix_sum + self.alpha*vocab_size)\n",
        "\n",
        "\n",
        "      #Returns the smoothed probability of a single ngram, using Laplace Smoothing. Remember to handle the special case of n=1\n",
        "      #Use the class variables we defined in the build function. It is suggested to implement the build function before this one.\n",
        "\n",
        "    \n",
        "    #TODO:\n",
        "    def build(self):\n",
        "        \n",
        "        #Returns a n-gram (could be a unigram) dict with n-gram tuples as keys and probabilities as values. \n",
        "        #It could be a unigram model as well\n",
        "        ngrams = get_ngrams(self.train_data,n=self.n)\n",
        "        prefix_ngrams = get_ngrams(self.train_data,n = self.n-1)\n",
        "\n",
        "        self.n_grams_counts = Counter(ngrams)\n",
        "        self.prefix_counts = Counter(prefix_ngrams)\n",
        "\n",
        "        prob = dict()\n",
        "        for n_gram in self.n_grams_counts:\n",
        "          prob[n_gram] = self.get_smooth_probabilities(n_gram)\n",
        "\n",
        "        return prob"
      ],
      "metadata": {
        "id": "-YS-RbLznc5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Albert: N-Gram Language Model-Based Solver"
      ],
      "metadata": {
        "id": "pqlS4eMWGh8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Albert():\n",
        "  def __init__(self, model,n):\n",
        "    # I want to pass in a naive bayes n-gram model here.\n",
        "    #the probability \"p\" is the parameter we want to train\n",
        "    self.model = model\n",
        "    self.p = 0.03\n",
        "    self.n = n\n",
        "  \n",
        "  def check_probability(self, path, next):\n",
        "    candidate = path[-(self.n-1):] + next\n",
        "    return (candidate in self.model and self.model[candidate] >= self.p)\n",
        "  \n",
        "\n",
        "  def bfs(self, tile, adjlist, board, path, result, visited):\n",
        "    #INPUT\n",
        "    #tile : the root tile that we are starting from\n",
        "    #adjlist : adjacency list of our graph\n",
        "    #board : 2d matrix of our graph so accessing is easier\n",
        "    #path : the current accumulated letters for our words\n",
        "    #pathprob : should we add the log probability of the current path? will do it on second try\n",
        "    #result : the resulting set from the past\n",
        "    #visited : the tiles that we have already visited\n",
        "\n",
        "    #OUTPUT\n",
        "    #result : the resulting set after conducting bfs\n",
        "\n",
        "    #check if current path is a word\n",
        "    if(len(path)>3 and self.check_probability(path, \"\\n\")):\n",
        "      result.add(path + \"\\n\")\n",
        "\n",
        "    #check if extensions are a word\n",
        "    #for each neighbor\n",
        "    for neighbor in adjlist[tile]:\n",
        "        #if we haven't visited it yet, we do smth\n",
        "        #so if we've visited all the neighbors we just move on\n",
        "        if neighbor not in visited:\n",
        "            next = str(board[neighbor[0]][neighbor[1]])\n",
        "            #check probabilities\n",
        "            if(self.check_probability(path, next)):\n",
        "              new = path + next\n",
        "              temp = visited.copy()\n",
        "              temp.append(neighbor)\n",
        "              result = result | self.bfs(neighbor, adjlist, board, new, result, temp)\n",
        "    return result \n",
        "\n",
        "\n",
        "  def solve(self, board):\n",
        "      #INPUT\n",
        "      # board: a 2-d char array of n x n dimensions\n",
        "      # cutoff: the probability 0 < cutoff < 1, such that if the probability a character follows is lower than this cutoff we do not pursue this path\n",
        "\n",
        "      #OUTPUT\n",
        "      # result: a set of words found from the board\n",
        "\n",
        "      result = set()\n",
        "\n",
        "      #first, we want to make an adjacency list\n",
        "      adjlist = board_to_adjlist(board)\n",
        "      for tile in adjlist:\n",
        "        visited = [tile]\n",
        "        path = \"0\" + str(board[tile[0]][tile[1]])\n",
        "        found = self.bfs(tile, adjlist, board,path , set(), visited)\n",
        "        result = result | found\n",
        "         \n",
        "      return post_process(result)\n",
        "  \n",
        "  def train(self, boards, solutions):\n",
        "    #essentially, what we want to do here is solve each board\n",
        "    #its better to make our probability initially really small so that\n",
        "    #runtime isn't dogshit (it will take eons to run if we go through every single possible path)\n",
        "    #then our loss function will be p = p * log (wP/wR) (thinking about adding here, see which one does better), \n",
        "    # where wP is the weighted precision and wR is the weighted recall (this is based on wordhunt scores, eg 800 for 5 letter words)\n",
        "    #we keep going until we go through all the boards and solutions\n",
        "    #afterwards, print our final p-value to see where it ended up\n",
        "    return\n",
        "  \n",
        "\n",
        "  def evaluate(self, boards):\n",
        "    # boards: a list of boards (generated by the helper function generate_random_boards)\n",
        "    # this will contain a a row for every board; each row contains the precision, recall, and f1 of our solution against reference, in that order\n",
        "    summary_stats = []\n",
        "    epoch = 0\n",
        "    for board in boards:\n",
        "      print(\"epoch\", epoch, \":\\n\")\n",
        "      # TODO: FIX THE SYNTAX (ref_sol.solve is 100% not correct)\n",
        "      ref_sol = ref_sol.solve(board)\n",
        "      train_sol = self.solve(board)\n",
        "      # find precision, recall\n",
        "      prec = self.precision(train_sol, ref_sol)\n",
        "      rec = self.recall(train_sol, ref_sol)\n",
        "      f1 = (prec * rec)/(prec + rec)\n",
        "      print(\"Precision: \", prec, \"Recall: \", rec, \"F1\", f1)\n",
        "      summary_stats.append([prec, rec, f1])\n",
        "    return summary_stats"
      ],
      "metadata": {
        "id": "o_UOthuAT3C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alexei: Albert 2.0\n",
        "Alexei is also a n-gram based, model, but this time we will look at overall path probability, rather than localized n-gram probability."
      ],
      "metadata": {
        "id": "DFo04kN2b34V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Alexei():\n",
        "  def __init__(self, path , n, size):\n",
        "    # I want to pass in a naive bayes n-gram model here.\n",
        "    #the probability \"p\" is the parameter we want to train\n",
        "    lm = LanguageModel(n, path)\n",
        "    dictionary = Dictionary(path, size)\n",
        "    self.model = lm.model\n",
        "    self.p = self.find_cutoffs(dictionary.listed)\n",
        "    self.n = n\n",
        "  \n",
        "  def calculate_logprob(self, word, n):\n",
        "    word = \"0\" + word + \"\\n\"\n",
        "    result = 0\n",
        "    for i in range(len(word) - (n-1)):\n",
        "      result += math.log(self.model[word[i:i+n]])\n",
        "    return result\n",
        "  \n",
        "  def find_cutoffs(self, dictionary):\n",
        "    temp = dict()\n",
        "    result = dict()\n",
        "    for word in dictionary:\n",
        "      if (len(word) in temp):\n",
        "        temp[len(word)].append(self.calculate_logprob(word, 3))\n",
        "      else:\n",
        "        temp[len(word)] = [self.calculate_logprob(word, 3)]\n",
        "    for length,probabilities in temp.items():\n",
        "        result[length] = sum(probabilities)/len(probabilities)\n",
        "    return result\n",
        "  \n",
        "  def check_probability(self, path, pathprob, next):\n",
        "    length = len(path)\n",
        "    candidate = path[-(self.n-1):] + next\n",
        "    \n",
        "    if (candidate in self.model):\n",
        "      nextprob = math.log(self.model[candidate])\n",
        "      if (length == 2 or pathprob + nextprob >= self.p[length-1]):\n",
        "        return nextprob\n",
        "    return 0\n",
        "  \n",
        "\n",
        "  def bfs(self, tile, adjlist, board, path, pathprob, result, visited):\n",
        "    #INPUT\n",
        "    #tile : the root tile that we are starting from\n",
        "    #adjlist : adjacency list of our graph\n",
        "    #board : 2d matrix of our graph so accessing is easier\n",
        "    #path : the current accumulated letters for our words\n",
        "    #pathprob : should we add the log probability of the current path? will do it on second try\n",
        "    #result : the resulting set from the past\n",
        "    #visited : the tiles that we have already visited\n",
        "\n",
        "    #OUTPUT\n",
        "    #result : the resulting set after conducting bfs\n",
        "\n",
        "    #check if current path is a word\n",
        "    if(len(path)>3 and self.check_probability(path, pathprob,\"\\n\")):\n",
        "      result.add(path + \"\\n\")\n",
        "\n",
        "    #check if extensions are a word\n",
        "    #for each neighbor\n",
        "    for neighbor in adjlist[tile]:\n",
        "        #if we haven't visited it yet, we do smth\n",
        "        #so if we've visited all the neighbors we just move on\n",
        "        if neighbor not in visited:\n",
        "            next = str(board[neighbor[0]][neighbor[1]])\n",
        "            #check probabilities\n",
        "            nextprob = self.check_probability(path, pathprob, next)\n",
        "            if(nextprob):\n",
        "              new = path + next\n",
        "              temp = visited.copy()\n",
        "              temp.append(neighbor)\n",
        "              result = result | self.bfs(neighbor, adjlist, board, new, pathprob + nextprob, result, temp)\n",
        "    return result \n",
        "\n",
        "\n",
        "  def solve(self, board):\n",
        "      #INPUT\n",
        "      # board: a 2-d char array of n x n dimensions\n",
        "      # cutoff: the probability 0 < cutoff < 1, such that if the probability a character follows is lower than this cutoff we do not pursue this path\n",
        "\n",
        "      #OUTPUT\n",
        "      # result: a set of words found from the board\n",
        "\n",
        "      result = set()\n",
        "\n",
        "      #first, we want to make an adjacency list\n",
        "      adjlist = board_to_adjlist(board)\n",
        "      for tile in adjlist:\n",
        "        visited = [tile]\n",
        "        path = \"0\" + str(board[tile[0]][tile[1]])\n",
        "        found = self.bfs(tile, adjlist, board, path , 0, set(), visited)\n",
        "        result = result | found\n",
        "         \n",
        "      return post_process(result)\n",
        "  \n",
        "  def train(self, boards, solutions):\n",
        "    #essentially, what we want to do here is solve each board\n",
        "    #its better to make our probability initially really small so that\n",
        "    #runtime isn't dogshit (it will take eons to run if we go through every single possible path)\n",
        "    #then our loss function will be p = p * log (wP/wR) (thinking about adding here, see which one does better), \n",
        "    # where wP is the weighted precision and wR is the weighted recall (this is based on wordhunt scores, eg 800 for 5 letter words)\n",
        "    #we keep going until we go through all the boards and solutions\n",
        "    #afterwards, print our final p-value to see where it ended up\n",
        "    return\n",
        "  \n",
        "\n",
        "  def evaluate(self, boards):\n",
        "    # boards: a list of boards (generated by the helper function generate_random_boards)\n",
        "    # this will contain a a row for every board; each row contains the precision, recall, and f1 of our solution against reference, in that order\n",
        "    summary_stats = []\n",
        "    epoch = 0\n",
        "    for board in boards:\n",
        "      print(\"epoch\", epoch, \":\\n\")\n",
        "      # TODO: FIX THE SYNTAX (ref_sol.solve is 100% not correct)\n",
        "      ref_sol = ref_sol.solve(board)\n",
        "      train_sol = self.solve(board)\n",
        "      # find precision, recall\n",
        "      prec = self.precision(train_sol, ref_sol)\n",
        "      rec = self.recall(train_sol, ref_sol)\n",
        "      f1 = (prec * rec)/(prec + rec)\n",
        "      print(\"Precision: \", prec, \"Recall: \", rec, \"F1\", f1)\n",
        "      summary_stats.append([prec, rec, f1])\n",
        "    return summary_stats"
      ],
      "metadata": {
        "id": "hMmQaY4Cb9i-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Isaac: Dictionary-Based Solver"
      ],
      "metadata": {
        "id": "vSblfq6cGcR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Isaac():\n",
        "  def __init__(self, dictionary):\n",
        "    self.dictionary = dictionary.listed\n",
        "  \n",
        "\n",
        "  def dfs(self, word, tile, adjlist, visited, path, board):\n",
        "    if(path == len(word)):\n",
        "      return True\n",
        "    \n",
        "    for neighbor in adjlist[tile]:\n",
        "      if neighbor not in visited:\n",
        "        if board[neighbor[0]][neighbor[1]] == word[path]:\n",
        "          temp = visited.copy()\n",
        "          temp.append(neighbor)\n",
        "          if(self.dfs(word,neighbor, adjlist, temp, path + 1, board)):\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "  def solve(self, board):\n",
        "    result = []\n",
        "    adjlist = board_to_adjlist(board)\n",
        "    lst = board_to_list(board)\n",
        "    ref = board_to_dict(board)\n",
        "    #im going to make a dictionary for easy access\n",
        "\n",
        "    for word in self.dictionary:\n",
        "      if len(word) > 2 and len(word) <= 16 and exists(word, lst):\n",
        "        for start in ref[word[0]]:\n",
        "          if(self.dfs(word, start, adjlist, [start], 1, board)):\n",
        "            result.append(word)\n",
        "            break\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "evQruf96TK1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Begins!"
      ],
      "metadata": {
        "id": "RRKSl8a9GWbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tester = [['A','N','T','E'], ['E','T','A','A'], ['R','D','N','N'], ['L','L','E','K']]"
      ],
      "metadata": {
        "id": "mjlDHyzbVki1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = Dictionary(\"dictionary.txt\",10000)"
      ],
      "metadata": {
        "id": "Rz-8XChF-zAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = LanguageModel(3, \"dictionary.txt\")\n",
        "albert = Albert(lm.model, 3)"
      ],
      "metadata": {
        "id": "t4CxuO3kSQud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "tim = 0\n",
        "for i in range(100):\n",
        "  tic = time.perf_counter()\n",
        "  result = albert.solve(tester)\n",
        "  result = validate(dictionary, result)\n",
        "  toc = time.perf_counter()\n",
        "  tim += (toc - tic)\n",
        "tim = tim/100\n",
        "print(tim)\n",
        "'''\n",
        "tic = time.perf_counter()\n",
        "result = albert.solve(tester)\n",
        "result = sorted(result, key = len, reverse = True)\n",
        "print(len(result))\n",
        "result = validate(dictionary, result)\n",
        "toc = time.perf_counter()\n",
        "print(toc - tic)\n",
        "result = sorted(result, key = len, reverse = True)\n",
        "print(result)\n",
        "print(len(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZlroFIi8_dP",
        "outputId": "f37587ae-a0d4-432e-fd62-b2dc2deae5e2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8606\n",
            "1.2385074430021632\n",
            "['ENTENTE', 'ANDANTE', 'TANNATE', 'DENTATE', 'NATTER', 'LENDER', 'NATANT', 'TANNED', 'LENTEN', 'ENATE', 'ANTRE', 'RENTE', 'ENDER', 'REATA', 'TATER', 'EATER', 'ANTED', 'DATER', 'KENTE', 'ENTER', 'EATEN', 'ANTE', 'DATA', 'ANNA', 'TATE', 'DELL', 'LENT', 'RENT', 'DEAN', 'KENT', 'DENT', 'DATE', 'REDE', 'ANTA', 'TENT', 'LEND', 'NANA', 'ELL', 'ANT', 'TED', 'TEN', 'RET', 'ATE', 'ETA', 'DEN', 'END', 'NAN', 'KEN', 'ANE', 'TAN', 'AND', 'DAN', 'DEL', 'LED', 'NET', 'ANA', 'RED']\n",
            "57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alexei = Alexei(\"dictionary.txt\", 3,10000)"
      ],
      "metadata": {
        "id": "DB1i-3pNe2Qh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tic = time.perf_counter()\n",
        "result = alexei.solve(tester)\n",
        "result = sorted(result, key = len, reverse = True)\n",
        "print(len(result))\n",
        "result = validate(dictionary, result)\n",
        "toc = time.perf_counter()\n",
        "print(toc - tic)\n",
        "result = sorted(result, key = len, reverse = True)\n",
        "print(result)\n",
        "print(len(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9u5Bl-PfEvr",
        "outputId": "1d1ea836-e271-4232-d7c5-0004e807f628"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1292\n",
            "0.07530292999945232\n",
            "['ANTEATER', 'ANTEDATE', 'ANDANTE', 'DENTATE', 'TANNATE', 'ENTENTE', 'NATTER', 'TANKED', 'LENDER', 'NATANT', 'TEATED', 'TANNED', 'LENTEN', 'REDATE', 'EATER', 'ENATE', 'ELDER', 'ANTED', 'DATER', 'KENTE', 'ANTRE', 'KNELL', 'REATA', 'RENTE', 'TATER', 'ENDER', 'REDAN', 'ENTER', 'DELL', 'LENT', 'RENT', 'DATE', 'TENT', 'ANTE', 'DEAN', 'REDE', 'KENT', 'ANTA', 'TANK', 'TATE', 'LEND', 'DENT', 'DAN', 'ELD', 'END', 'NAN', 'ELL', 'TEN', 'DEL', 'LED', 'NET', 'KEN', 'ANA', 'ANE', 'TAN', 'RET', 'ANT', 'AND', 'RED', 'ATE', 'DEN', 'TAT', 'TED']\n",
            "63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "isaac = Isaac(dictionary)"
      ],
      "metadata": {
        "id": "8y-59NsNSW2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tic = time.perf_counter()\n",
        "result = isaac.solve(tester)\n",
        "result = sorted(result, key = len, reverse = True)\n",
        "print(len(result))\n",
        "result = validate(dictionary, result)\n",
        "toc = time.perf_counter()\n",
        "print(toc - tic)\n",
        "result = sorted(result, key = len, reverse = True)\n",
        "print(result)\n",
        "print(len(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuGsQtga6NvA",
        "outputId": "2aa8e86f-fb59-42ca-e712-4257feafd3cc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87\n",
            "0.49203074099932564\n",
            "['ANTEATER', 'ANTEDATE', 'EDENTATE', 'ANDANTE', 'DENTATE', 'ENTENTE', 'TANNATE', 'ADNATE', 'ANANKE', 'LENDER', 'LENTEN', 'NATANT', 'NATTER', 'REDATE', 'TANKED', 'TANNED', 'TEATED', 'ANENT', 'ANTAE', 'ANTED', 'ANTRE', 'DATER', 'EATEN', 'EATER', 'ELDER', 'ENATE', 'ENDER', 'ENTER', 'KENTE', 'KNELL', 'REATA', 'REDAN', 'RENTE', 'TATER', 'ANNA', 'ANTA', 'ANTE', 'DANK', 'DATA', 'DATE', 'DEAN', 'DELL', 'DENT', 'ETNA', 'KENT', 'LEND', 'LENT', 'NAAN', 'NANA', 'NEAT', 'NERD', 'NETT', 'REDE', 'RENT', 'TANK', 'TATE', 'TEAT', 'TENT', 'ANA', 'AND', 'ANE', 'ANT', 'ATE', 'ATT', 'DAN', 'DEL', 'DEN', 'EAT', 'ELD', 'ELL', 'END', 'ETA', 'KEN', 'LED', 'LEK', 'NAE', 'NAN', 'NET', 'RED', 'RET', 'TAD', 'TAE', 'TAN', 'TAT', 'TEA', 'TED', 'TEN']\n",
            "87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I explore the relationship between probability and word length here."
      ],
      "metadata": {
        "id": "5P4lUbuwhbrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#idk what this is but im gonna try it\n",
        "def calculate_logprob(word, n):\n",
        "  word = \"0\" + word + \"\\n\"\n",
        "  result = 0\n",
        "  for i in range(len(word) - (n-1)):\n",
        "    result += math.log(lm.model[word[i:i+n]])\n",
        "  return result\n",
        "\n",
        "temp = dict()\n",
        "result = dict()\n",
        "for word in dictionary.listed:\n",
        "  if (len(word) in temp):\n",
        "    temp[len(word)].append(calculate_logprob(word, 3))\n",
        "  else:\n",
        "    temp[len(word)] = [calculate_logprob(word, 3)]\n",
        "for length,probabilities in temp.items():\n",
        "    result[length] = sum(probabilities)/len(probabilities)\n",
        "print(result)\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEbnyPOWICSv",
        "outputId": "0deddb2c-f34c-42d2-ec53-55c1e3eee068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{2: -6.414554690303605, 3: -8.604237692845928, 5: -11.882632491842879, 6: -13.657852758752027, 4: -10.181407818829243, 8: -17.353987041081496, 9: -19.168973224840833, 10: -20.713177139715725, 7: -15.361038521793596, 11: -22.387239925257386, 12: -24.11778948221498, 13: -25.859070851168124, 14: -27.60361337652588, 15: -29.336418250737132}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "\n",
        "lists = sorted(result.items()) # sorted by key, return a list of tuples\n",
        "\n",
        "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ENF6xVL9LisP",
        "outputId": "2ce89a62-04d9-42dc-9719-67d03aee19b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MASS TESTING\n",
        "The idea here is we're going to generate a bunch of random boards and solve each one. We will first evaluate on a few easy metrics that we have already looked at previously\n",
        "\n",
        "\n",
        "1.   Number Correct/Number Total\n",
        "2.   Number Correct/Number Generated\n",
        "3.   Time to Generate\n",
        "\n"
      ],
      "metadata": {
        "id": "RAv2cEfyhrax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(n):\n",
        "  #summary statistics of albert\n",
        "  albert_precision = 0\n",
        "  albert_acc = 0\n",
        "  albert_time = 0\n",
        "  #summary statistics of alexei\n",
        "  alexei_precision = 0\n",
        "  alexei_acc = 0\n",
        "  alexei_time = 0\n",
        "  #summary statistics of isaac\n",
        "  isaac_precision = 1\n",
        "  isaac_acc = 1\n",
        "  isaac_time = 0 \n",
        "\n",
        "  batch = generate_random_boards(n,4,4)\n",
        "  for board in batch:\n",
        "\n",
        "    #TESTING FOR ISAAC - OUR CONTROL SOLUTION\n",
        "    tic = time.perf_counter()\n",
        "    isaac_res = isaac.solve(board)\n",
        "    toc = time.perf_counter()\n",
        "    isaac_time += (toc - tic)\n",
        "    refsol = len(isaac_res)\n",
        "\n",
        "\n",
        "    #TESTING FOR ALBERT - OUR FIRST VERSION\n",
        "    tic = time.perf_counter()\n",
        "    albert_res = albert.solve(board)\n",
        "    tot_albert = len(albert_res)\n",
        "    albert_res = validate(dictionary, albert_res)\n",
        "    red_albert = len(albert_res)\n",
        "    toc = time.perf_counter()\n",
        "    albert_time += (toc - tic)\n",
        "    albert_precision += red_albert/tot_albert\n",
        "    albert_acc += red_albert/refsol\n",
        "\n",
        "\n",
        "    #TESTING FOR ALEXEI - OUR SECOND VERSION\n",
        "    tic = time.perf_counter()\n",
        "    alexei_res = alexei.solve(board)\n",
        "    tot_alexei = len(alexei_res)\n",
        "    alexei_res = validate(dictionary, alexei_res)\n",
        "    red_alexei = len(alexei_res)\n",
        "    toc = time.perf_counter()\n",
        "    alexei_time += (toc - tic)\n",
        "    alexei_precision += red_alexei/tot_alexei\n",
        "    alexei_acc += red_alexei/refsol\n",
        "    \n",
        "  #printing the final statistics\n",
        "  print(\"FINAL SUMMARY STATISTICS\")\n",
        "  print(\"########################\")\n",
        "  print(\"ISAAC REFERENCE STATISTICS\")\n",
        "  print(\"ISAAC NUMBER CORRECT/NUMBER TOTAL: {}\".format(isaac_precision))\n",
        "  print(\"ISAAC NUMBER CORRECT/NUMBER GENERATED: {}\".format(isaac_acc))\n",
        "  print(\"ISAAC AVERAGE TIME TO SOLVE: {}\".format(isaac_time/n))\n",
        "  print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "  print(\"ALBERT REFERENCE STATISTICS\")\n",
        "  print(\"ALBERT NUMBER CORRECT/NUMBER TOTAL: {}\".format(albert_precision/n))\n",
        "  print(\"ALBERT NUMBER CORRECT/NUMBER GENERATED: {}\".format(albert_acc/n))\n",
        "  print(\"ALBERT AVERAGE TIME TO SOLVE: {}\".format(albert_time/n))\n",
        "  print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "  print(\"ALEXEI REFERENCE STATISTICS\")\n",
        "  print(\"ALEXEI NUMBER CORRECT/NUMBER TOTAL: {}\".format(alexei_precision/n))\n",
        "  print(\"ALEXEI NUMBER CORRECT/NUMBER GENERATED: {}\".format(alexei_acc/n))\n",
        "  print(\"ALEXEI AVERAGE TIME TO SOLVE: {}\".format(alexei_time/n))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gspg4MZbiTv_"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkU1aoklk2H9",
        "outputId": "98d9690b-ab5a-4e84-ef22-0bc6aad749e0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL SUMMARY STATISTICS\n",
            "########################\n",
            "ISAAC REFERENCE STATISTICS\n",
            "ISAAC NUMBER CORRECT/NUMBER TOTAL: 1\n",
            "ISAAC NUMBER CORRECT/NUMBER GENERATED: 1\n",
            "ISAAC AVERAGE TIME TO SOLVE: 0.42252371575017605\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ALBERT REFERENCE STATISTICS\n",
            "ALBERT NUMBER CORRECT/NUMBER TOTAL: 0.06183175207702251\n",
            "ALBERT NUMBER CORRECT/NUMBER GENERATED: 0.45496053016798876\n",
            "ALBERT AVERAGE TIME TO SOLVE: 0.09361850172004779\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "ALEXEI REFERENCE STATISTICS\n",
            "ALEXEI NUMBER CORRECT/NUMBER TOTAL: 0.18300540722741712\n",
            "ALEXEI NUMBER CORRECT/NUMBER GENERATED: 0.5073200886783271\n",
            "ALEXEI AVERAGE TIME TO SOLVE: 0.015043038050134783\n"
          ]
        }
      ]
    }
  ]
}